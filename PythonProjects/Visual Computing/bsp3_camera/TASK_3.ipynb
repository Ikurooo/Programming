{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera sensors\n",
    "\n",
    "Welcome to the third exercise in Einf√ºhrung in Visual Computing. This exercise gives you a basic knowledge and understanding of image processing, mainly with numpy. We will cover how to operate on images which are two dimensional numpy arrays in Python. \n",
    "\n",
    "The Jupyter Notebook provides the general programm sequence, once everything is implemented, you should see results as described in the main task description. For the later parts of the exercise, a GUI is provided which should open once you execute the respective cells."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Task 2, we first import everything we will need in our Jupyter Notebook. It is recommended to first import built in libraries (e.g. os, argparse, etc.), then third party libraries like numpy or matplotlib and last self-implemented python resources (see functions 'evc_xxx' or GUI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport evc_black_level, evc_histogram_clipping, evc_white_balance, evc_demosaic, evc_gamma_correction, evc_compute_binary, GUI.gui_white_balance, GUI.gui_gamma_correction, GUI.gui_gamma_histogram_clipping, GUI.gui_shared\n",
    "#%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from GUI.ipython_helper import imEmbed\n",
    "\n",
    "import evc_black_level, evc_histogram_clipping, evc_white_balance, evc_demosaic, evc_gamma_correction, evc_compute_binary\n",
    "from GUI import gui_white_balance, gui_gamma_correction, gui_gamma_histogram_clipping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select image file\n",
    "First, define the path of the image you want to deal with below. They are located in the images directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '0/IMG_5.tiff'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black Level\n",
    "Since all of our images are saved as 16-bit TIFFs and we are provided with some metadata, we first will use this and extract the blacklevel and \"as-shot-neutral\" to transform the image. In evc_black_level, complete the function evc_read_file_info which should return those two variables by iterating over the metadata dictionary provided by PIL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1439 (0.454302, 1.0, 0.657419)\n"
     ]
    }
   ],
   "source": [
    "pattern = 'RGGB'\n",
    "img_pil = Image.open(file)\n",
    "\n",
    "blackLevel, asShotNeutral = evc_black_level.evc_read_file_info(file)\n",
    "print(blackLevel, asShotNeutral)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, implement evc_transform_colors which maps the image from [blackLevel, 65535] to [0, 1]. Pay attention to the datatype!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "(1738, 1158)\n"
     ]
    }
   ],
   "source": [
    "img = np.asarray(img_pil)\n",
    "img_transformed_color = evc_black_level.evc_transform_colors(img, blackLevel)\n",
    "print(np.max(img_transformed_color), np.min(img_transformed_color))\n",
    "print(img_transformed_color.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demosaic\n",
    "Once our image is in the correct domain, we can apply the preprocessing: The images are captures by cameras using sensors with color filters and specific patterns commonly known as Bayer Patterns. As shown in the task description, your images include one of four different patterns (RGGB, BGGR, GRBG, GBRG). Implement the correct pattern for your task description (trying out all four) in evc_demosaic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, g, b = evc_demosaic.evc_demosaic_pattern(img_transformed_color, pattern)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we now obtained the red, blue and green channel, we can make use of the 'asShotNeutral' from above: In evc_demosaic.evc_transform_neutral, divide each channel by its respective value of the variable asShotNeutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_trans, G_trans, B_trans = evc_demosaic.evc_transform_neutral(r,g,b, asShotNeutral)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are almost done with the preprocessing: Due to the bayer pattern, we only have quarter/half of the information (=pixels) for each channel. The remaining pixels are still zero: Your task is to implement the interpolation in evc_interpolate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_inter, G_inter, B_inter = evc_demosaic.evc_interpolate(R_trans, G_trans, B_trans)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In evc_concat, concatenate the red, green, and blue channel so we can plot the image below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivan\\AppData\\Local\\Temp\\ipykernel_4404\\1052102565.py:2: RuntimeWarning: invalid value encountered in divide\n",
      "  imEmbed(img_demosaic / np.max(img_demosaic))\n",
      "c:\\py\\evc\\bsp3_camera\\GUI\\ipython_helper.py:8: RuntimeWarning: invalid value encountered in cast\n",
      "  img = np.clip(img*255,0,255).astype(np.uint8)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAH0CAIAAAA2V+guAAAB+klEQVR4nO3BAQEAAACCIP+vbkhAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPBsoYkAAckmW24AAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_demosaic = evc_demosaic.evc_concat(R_inter, G_inter, B_inter)\n",
    "imEmbed(img_demosaic / np.max(img_demosaic))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White balance\n",
    "\n",
    "We're done with the preprocessing, now we focus on enhancing the image. First, we implement white balancing. In evc_white_balance, implement the function 'evc_white_balance' and pay attention you properly deal with zeros. Once your implementation is correct, the GUI should guide you through the white balancing process and a nice image should be plotted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAH0CAIAAAA2V+guAAAB+klEQVR4nO3BAQEAAACCIP+vbkhAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPBsoYkAAckmW24AAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_wb = gui_white_balance.gui_white_balance(img_demosaic)\n",
    "imEmbed(img_wb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma correction\n",
    "Since the human eye has different perception for dark and bright areas (== non-linear), we can target this by a non-linear transformation known as gamma-correction (f(x) = x^i, where i is a parameter). Implement the gamma correction and apply the gamma correction via the provided gui to the white balanced image.\n",
    "\n",
    "Secondly, we deal with a gamma correction which focuses on brightness: Refer to the task description and implement the corresponding functions. In the GUI is a checkbox to select the corresponding algorithm for the gamma correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAH0CAIAAAA2V+guAAAB+klEQVR4nO3BAQEAAACCIP+vbkhAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPBsoYkAAckmW24AAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_gamma_corrected = gui_gamma_correction.gui_gamma_correction(img_wb)\n",
    "imEmbed(img_gamma_corrected)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrast enhancement\n",
    "Gamma corrected images usually suffer from low contrast - we can tackle this issue by implementing contrast enhancement. Mathematically, as discussed in the lecture, this is implemented as a linear transformation. Dark areas are mapped to zero, bright areas to one, the remaining parts of the image are then assigned to values between [0,1] which is perceived as high contrast. In the following tasks, you should implement the binarization in order to set the values which should be 0/1 as well as the histogramm clipping which performs the actual contrast enhancement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\py\\evc\\bsp3_camera\\evc_histogram_clipping.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  new_low /= max_intensity\n",
      "c:\\py\\evc\\bsp3_camera\\evc_histogram_clipping.py:31: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  new_high /= max_intensity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low: 0, high: 1\n"
     ]
    }
   ],
   "source": [
    "low, high = gui_gamma_histogram_clipping.gui_gamma_histogram_clipping(img_gamma_corrected)\n",
    "print (f'low: {low}, high: {high}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "newLow, newHigh = evc_histogram_clipping.evc_prepare_histogram_range(img_gamma_corrected, low, high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\py\\evc\\bsp3_camera\\evc_histogram_clipping.py:31: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  new_high /= max_intensity\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAH0CAIAAAA2V+guAAAB+klEQVR4nO3BAQEAAACCIP+vbkhAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPBsoYkAAckmW24AAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_norm = evc_histogram_clipping.evc_transform_histogram(img_gamma_corrected, newLow, newHigh)\n",
    "imEmbed(img_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAH0CAIAAAA2V+guAAAB+klEQVR4nO3BAQEAAACCIP+vbkhAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPBsoYkAAckmW24AAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_clipped = evc_histogram_clipping.evc_clip_histogram(img_norm)\n",
    "imEmbed(img_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfe7cb13bc9d71c5175561fc5240999a6a06ca970085fc8402a8a150784751f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
