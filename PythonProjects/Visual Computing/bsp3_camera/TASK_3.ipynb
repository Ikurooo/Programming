{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera sensors\n",
    "\n",
    "Welcome to the third exercise in EinfÃ¼hrung in Visual Computing. This exercise gives you a basic knowledge and understanding of image processing, mainly with numpy. We will cover how to operate on images which are two dimensional numpy arrays in Python. \n",
    "\n",
    "The Jupyter Notebook provides the general programm sequence, once everything is implemented, you should see results as described in the main task description. For the later parts of the exercise, a GUI is provided which should open once you execute the respective cells."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Task 2, we first import everything we will need in our Jupyter Notebook. It is recommended to first import built in libraries (e.g. os, argparse, etc.), then third party libraries like numpy or matplotlib and last self-implemented python resources (see functions 'evc_xxx' or GUI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Failed to import any of the following Qt binding modules: PyQt6, PySide6, PyQt5, PySide2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mGUI\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mipython_helper\u001b[39;00m \u001b[39mimport\u001b[39;00m imEmbed\n\u001b[0;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mevc_black_level\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mevc_histogram_clipping\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mevc_white_balance\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mevc_demosaic\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mevc_gamma_correction\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mevc_compute_binary\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mGUI\u001b[39;00m \u001b[39mimport\u001b[39;00m gui_white_balance, gui_gamma_correction, gui_gamma_histogram_clipping\n",
      "File \u001b[1;32mc:\\py\\evc\\bsp3_camera\\GUI\\gui_white_balance.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mevc_white_balance\u001b[39;00m \u001b[39mimport\u001b[39;00m evc_white_balance\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackends\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_qtagg\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvas\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackends\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_qtagg\u001b[39;00m \u001b[39mimport\u001b[39;00m \\\n\u001b[0;32m     11\u001b[0m     NavigationToolbar2QT \u001b[39mas\u001b[39;00m NavigationToolbar\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackends\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mqt_compat\u001b[39;00m \u001b[39mimport\u001b[39;00m QtWidgets\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\backends\\backend_qtagg.py:9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mctypes\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m Bbox\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mqt_compat\u001b[39;00m \u001b[39mimport\u001b[39;00m QT_API, _enum\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbackend_agg\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasAgg\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbackend_qt\u001b[39;00m \u001b[39mimport\u001b[39;00m QtCore, QtGui, _BackendQT, FigureCanvasQT\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\backends\\qt_compat.py:135\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m    136\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFailed to import any of the following Qt binding modules: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m             \u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(_ETS\u001b[39m.\u001b[39mvalues())))\n\u001b[0;32m    138\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# We should not get there.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnexpected QT_API: \u001b[39m\u001b[39m{\u001b[39;00mQT_API\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import any of the following Qt binding modules: PyQt6, PySide6, PyQt5, PySide2"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport evc_black_level, evc_histogram_clipping, evc_white_balance, evc_demosaic, evc_gamma_correction, evc_compute_binary, GUI.gui_white_balance, GUI.gui_gamma_correction, GUI.gui_gamma_histogram_clipping, GUI.gui_shared\n",
    "#%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from GUI.ipython_helper import imEmbed\n",
    "\n",
    "import evc_black_level, evc_histogram_clipping, evc_white_balance, evc_demosaic, evc_gamma_correction, evc_compute_binary\n",
    "from GUI import gui_white_balance, gui_gamma_correction, gui_gamma_histogram_clipping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select image file\n",
    "First, define the path of the image you want to deal with below. They are located in the images directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../0/IMG_5.tiff'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black Level\n",
    "Since all of our images are saved as 16-bit TIFFs and we are provided with some metadata, we first will use this and extract the blacklevel and \"as-shot-neutral\" to transform the image. In evc_black_level, complete the function evc_read_file_info which should return those two variables by iterating over the metadata dictionary provided by PIL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'BGGR'\n",
    "img_pil = Image.open(file)\n",
    "\n",
    "blackLevel, asShotNeutral = evc_black_level.evc_read_file_info(file)\n",
    "print(blackLevel, asShotNeutral)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, implement evc_transform_colors which maps the image from [blackLevel, 65535] to [0, 1]. Pay attention to the datatype!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.asarray(img_pil)\n",
    "img_transformed_color = evc_black_level.evc_transform_colors(img, blackLevel)\n",
    "print(np.max(img_transformed_color), np.min(img_transformed_color))\n",
    "print(img_transformed_color.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demosaic\n",
    "Once our image is in the correct domain, we can apply the preprocessing: The images are captures by cameras using sensors with color filters and specific patterns commonly known as Bayer Patterns. As shown in the task description, your images include one of four different patterns (RGGB, BGGR, GRBG, GBRG). Implement the correct pattern for your task description (trying out all four) in evc_demosaic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, g, b = evc_demosaic.evc_demosaic_pattern(img_transformed_color, pattern)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we now obtained the red, blue and green channel, we can make use of the 'asShotNeutral' from above: In evc_demosaic.evc_transform_neutral, divide each channel by its respective value of the variable asShotNeutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_trans, G_trans, B_trans = evc_demosaic.evc_transform_neutral(r,g,b, asShotNeutral)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are almost done with the preprocessing: Due to the bayer pattern, we only have quarter/half of the information (=pixels) for each channel. The remaining pixels are still zero: Your task is to implement the interpolation in evc_interpolate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_inter, G_inter, B_inter = evc_demosaic.evc_interpolate(R_trans, G_trans, B_trans)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In evc_concat, concatenate the red, green, and blue channel so we can plot the image below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_demosaic = evc_demosaic.evc_concat(R_inter, G_inter, B_inter)\n",
    "imEmbed(img_demosaic / np.max(img_demosaic))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White balance\n",
    "\n",
    "We're done with the preprocessing, now we focus on enhancing the image. First, we implement white balancing. In evc_white_balance, implement the function 'evc_white_balance' and pay attention you properly deal with zeros. Once your implementation is correct, the GUI should guide you through the white balancing process and a nice image should be plotted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_wb = gui_white_balance.gui_white_balance(img_demosaic)\n",
    "imEmbed(img_wb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma correction\n",
    "Since the human eye has different perception for dark and bright areas (== non-linear), we can target this by a non-linear transformation known as gamma-correction (f(x) = x^i, where i is a parameter). Implement the gamma correction and apply the gamma correction via the provided gui to the white balanced image.\n",
    "\n",
    "Secondly, we deal with a gamma correction which focuses on brightness: Refer to the task description and implement the corresponding functions. In the GUI is a checkbox to select the corresponding algorithm for the gamma correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gamma_corrected = gui_gamma_correction.gui_gamma_correction(img_wb)\n",
    "imEmbed(img_gamma_corrected)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrast enhancement\n",
    "Gamma corrected images usually suffer from low contrast - we can tackle this issue by implementing contrast enhancement. Mathematically, as discussed in the lecture, this is implemented as a linear transformation. Dark areas are mapped to zero, bright areas to one, the remaining parts of the image are then assigned to values between [0,1] which is perceived as high contrast. In the following tasks, you should implement the binarization in order to set the values which should be 0/1 as well as the histogramm clipping which performs the actual contrast enhancement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low, high = gui_gamma_histogram_clipping.gui_gamma_histogram_clipping(img_gamma_corrected)\n",
    "print (f'low: {low}, high: {high}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newLow, newHigh = evc_histogram_clipping.evc_prepare_histogram_range(img_gamma_corrected, low, high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_norm = evc_histogram_clipping.evc_transform_histogram(img_gamma_corrected, newLow, newHigh)\n",
    "imEmbed(img_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_clipped = evc_histogram_clipping.evc_clip_histogram(img_norm)\n",
    "imEmbed(img_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfe7cb13bc9d71c5175561fc5240999a6a06ca970085fc8402a8a150784751f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
